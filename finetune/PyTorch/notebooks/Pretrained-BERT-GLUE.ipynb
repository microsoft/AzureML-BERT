{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Pretrained BERT on AzureML with GLUE Dataset\n",
    "This notebook contains an end-to-end walkthrough of using Azure Machine Learning Service to run [PyTorch reimplementation](https://github.com/huggingface/pytorch-pretrained-BERT) of [Google's TensorFlow repository for the BERT model](https://github.com/google-research/bert) developed by Hugging Face.\n",
    "\n",
    "You will find the following contents:\n",
    "- Download GLUE dataset on the remote compute and store them in Azure storage\n",
    "- Speep-up fine-tuning BERT for GLUE dataset on AzureML GPU clusters\n",
    "- Further fine-tune BERT wtih AzureML hyperparameter optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning (AML)\n",
    "\n",
    "- Install the Python SDK:  make sure to install notebook, and contrib\n",
    "```\n",
    "conda create -n azureml -y Python=3.6\n",
    "source activate azureml\n",
    "pip install --upgrade azureml-sdk[notebooks,contrib] \n",
    "conda install ipywidgets\n",
    "jupyter nbextension install --py --user azureml.widgets\n",
    "jupyter nbextension enable azureml.widgets --user --py\n",
    "```\n",
    "\n",
    "You will need to restart jupyter after this\n",
    "Detailed instructions are here: https://docs.microsoft.com/en-us/azure/machine-learning/service/quickstart-create-workspace-with-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "To create or access an Azure ML Workspace, you will need to import the AML library and the following information:\n",
    "* A name for your workspace\n",
    "* Your subscription id\n",
    "* The resource group name\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step or create a new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "workspace_name = ''\n",
    "subscription_id = ''\n",
    "resource_group_name = ''\n",
    "location = ''\n",
    "\n",
    "ws = Workspace._get_or_create(workspace_name,\n",
    "                             subscription_id=subscription_id,\n",
    "                             resource_group=resource_group_name,\n",
    "                             location=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed PyTorch tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'BERT-GLUE'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download GLUE dataset on the remote compute\n",
    "\n",
    "Before we start to fine-tune the pretained BERT model, we need to download the [GLUE data](https://gluebenchmark.com/tasks) by running the [script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e) and unpack it to an Azure Blob container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AzureML datastore to collect training dataset\n",
    "\n",
    "To make data accessible for remote training, AML provides a convenient way to do so via a [Datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data). The datastore provides a mechanism for you to upload/download data to Azure Storage, and interact with it from your remote compute targets.\n",
    "\n",
    "Each workspace is associated with a default Azure Blob datastore named `'workspaceblobstore'`. In this work, we use this default datastore to collect the GLUE training dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore(ws, 'workspaceblobstore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './pytorch-pretrained-BERT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a local clone of the original [PyTorch reimplementation](https://github.com/huggingface/pytorch-pretrained-BERT) repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b v0.4.0 https://github.com/huggingface/pytorch-pretrained-BERT.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to run the [script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e) to download the [GLUE data](https://gluebenchmark.com/tasks) in the mounted Azure Blob container. In our example, we only download `MRPC` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, os\n",
    "urllib.request.urlretrieve( 'https://raw.githubusercontent.com/nyu-mll/jiant/master/scripts/download_glue_data.py', filename='./download_glue_data.py')\n",
    "import download_glue_data\n",
    "download_glue_data.main([\"--tasks\", \"MRPC\", \"--data_dir\",\"./glue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that, if you receive `UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 1183: character maps to <undefined>`. Please modify all `'with open(...)'` operations in the downloaded `download_glue_data.py` to `'open(.., encoding=\"utf8\")'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will upload the training data to the path ./glue on the default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.upload(src_dir='./glue', target_path='./glue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning BERT with Distributed Training\n",
    "As our `GLUE` dataset are ready in Azure storage, we can start the fine-tune the model by exploting the power of distributed training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a GPU remote compute target\n",
    "\n",
    "We need to create a GPU [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) to perform the fine-tuning. In this example, we create an AmlCompute cluster as our training compute resource. Please find the information of Azure VM size in below table.\n",
    "\n",
    "\n",
    "|    VM Size    \t| CPU \t|   GPU   \t| Storage (SSD) \t| GPU memory \t| InfiniBand  \t|\n",
    "|:-------------:\t|:---:\t|:-------:\t|:-------------:\t|:----------:\t|:----------:\t|\n",
    "|  Standard_NC6 \t|  6  \t| 1 x K80 \t|    340 GiB    \t|    8 GiB   \t|      No   \t|\n",
    "| Standard_NC12 \t|  12 \t| 2 x K80 \t|    680 GiB    \t|   16 GiB   \t|      No   \t|\n",
    "| Standard_NC24 \t|  24 \t| 4 x K80 \t|    1440 GiB   \t|   32 GiB   \t|      No   \t|\n",
    "| Standard_NC24r \t|  24 \t| 4 x K80 \t|    1440 GiB   \t|   32 GiB   \t|      Yes   \t|\n",
    "| Standard_NC6s_v3 \t|  6  \t| 1 x V100 \t|    736 GiB    \t|   16 GiB   \t|      No   \t|\n",
    "| Standard_NC12s_v3 |  12 \t| 2 x V100 \t|    1474 GiB   \t|   32 GiB   \t|      No   \t|\n",
    "| Standard_NC24s_v3 |  24 \t| 4 x V100 \t|    2948 GiB   \t|   64 GiB   \t|      No   \t|\n",
    "| Standard_NC24rs_v3|  24 \t| 4 x V100 \t|    2948 GiB   \t|   64 GiB   \t|      Yes   \t|\n",
    "\n",
    "\n",
    "***Note that*** you need to request NCv3-serie quota if you would like to use NVIDIA Tesla V100 \n",
    "\n",
    "This code creates a cluster for you if it does not already exist in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "gpu_cluster_name = \"nc24Cluster\"\n",
    "\n",
    "try:\n",
    "    gpu_compute_target = ComputeTarget(workspace=ws, name=gpu_cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC24', max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    gpu_compute_target = ComputeTarget.create(ws, gpu_cluster_name, compute_config)\n",
    "    gpu_compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(gpu_compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PyTorch estimator for fine-tuning\n",
    "Let us create a new PyTorch estimator to run the fine-tuning script `run_classifier.py`, that is already provided at [the original repository](https://github.com/huggingface/pytorch-pretrained-BERT/blob/master/examples/run_classifier.py). Please refer [here](https://github.com/huggingface/pytorch-pretrained-BERT#fine-tuning-with-bert-running-the-examples) for more detail about the script. \n",
    "\n",
    "The original `run_classifier.py` script uses PyTorch distributed launch untility to launch multiple processes across nodes and GPUs. We prepared a modified version [run_classifier_azureml.py](./run_classifier_azureml.py) so that we can launch it based on AzureML build-in MPI backend.\n",
    "\n",
    "To use AML's tracking and metrics capabilities, we need to add a small amount of AzureML code inside the training script.\n",
    "\n",
    "In `run_classifier_azureml.py`, we will log some metrics to our AML run. To do so, we will access the AML run object within the script:\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "Further within `run_classifier_azureml.py`, we log learning rate, training loss and evaluation accuracy the model achieves as:\n",
    "```Python\n",
    "run.log('lr', np.float(args.learning_rate))\n",
    "...\n",
    "\n",
    "for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")): \n",
    "    ...\n",
    "    run.log('train_loss', np.float(loss))\n",
    "\n",
    "...\n",
    "\n",
    "result = {'eval_loss': eval_loss,\n",
    "          'eval_accuracy': eval_accuracy}\n",
    "for key in sorted(result.keys()):\n",
    "    run.log(key, str(result[key]))\n",
    "```\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section.\n",
    "\n",
    "Let's first copy the training script `run_classifier_azureml.py` into our project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copy('run_classifier_azureml.py', project_folder)\n",
    "shutil.copy('azureml_bert_util.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, AzureML PyTorch estimator can be defined as below. We use `azuremlsamples/bert:torch-1.0.0-apex-cuda9` as the base docker image with [dockerfile](./dockerfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder,\n",
    "                    compute_target=gpu_compute_target,\n",
    "                    script_params = {\n",
    "                          '--bert_model':'bert-base-cased',\n",
    "                          '--task_name': 'MRPC',\n",
    "                          '--data_dir': ds.path('glue/MRPC/').as_mount(),\n",
    "                          '--do_train' : '',\n",
    "                          '--do_eval': '',\n",
    "                          '--max_seq_length': 128,\n",
    "                          '--train_batch_size': 32,\n",
    "                          '--learning_rate': 2e-5,\n",
    "                          '--num_train_epochs': 3.0,\n",
    "                          '--output_dir': './outputs',\n",
    "                          '--seed':16\n",
    "                    },\n",
    "                    custom_docker_base_image='azuremlsamples/bert:torch-1.0.0-apex-cuda9',\n",
    "                    entry_script='run_classifier_azureml.py',\n",
    "                    node_count=1,\n",
    "                    process_count_per_node=4,\n",
    "                    distributed_backend='mpi',\n",
    "                    use_gpu=True)\n",
    "\n",
    "estimator._estimator_config.environment.python.user_managed_dependencies=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and Monitor your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve an average of **85% evaluation accuracy** with `MRPC dataset`, it requires **3** epochs when fine-tune with `BERT base` model. Below please find the elapsed time per epoch using deferent Azure GPU VMs with above hyperparameters\n",
    "\n",
    "|  GPU counts \t|    1 GPU    \t|         2 GPU \t| 4 GPU      \t|\n",
    "|------------:\t|:-----------:\t|--------------:\t|------------\t|\n",
    "|   NC-series \t| 191 s/epoch \t| 105 s/epoch   \t| 60 s/epoch \t|\n",
    "| NCv3-series \t|  36 s/epoch \t|    22 s/epoch \t| 13 s/epoch \t|\n",
    "| NCv3 with fp16|  32 s/epoch \t|    18 s/epoch \t| 12 s/epoch \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning BERT with Hyperparameter Tuning\n",
    "\n",
    "We would also like to optimize our hyperparameter, `learning rate`, using Azure Machine Learning's hyperparameter tuning capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a hyperparameter sweep\n",
    "First, we will define the hyperparameter space to sweep over. In this example we will use random sampling to try different configuration sets of hyperparameter to minimize our primary metric, the evaluation accuracy (`eval_accuracy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "import math\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        'learning_rate': loguniform(math.log(1e-4), math.log(1e-6)),\n",
    "    }\n",
    ")\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator=estimator,\n",
    "                                            hyperparameter_sampling=param_sampling, \n",
    "                                            primary_metric_name='eval_accuracy',\n",
    "                                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs=16,\n",
    "                                            max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor HyperDrive runs\n",
    "We can monitor the progress of the runs with the following Jupyter widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and register the best model\n",
    "Once all the runs complete, we can find the run that produced the model with the highest evaluation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print(best_run)\n",
    "print('Best Run is:\\n  accuracy: {0:.5f} \\n  Learning rate: {1:.8f}'.format(\n",
    "        best_run_metrics['eval_accuracy'][-1],\n",
    "        best_run_metrics['lr']\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the resulting optimal `learning_rate` with the value suggested by the [original implementation hyper-parameters](https://github.com/google-research/bert#sentence-and-sentence-pair-classification-tasks): 2e-5"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
